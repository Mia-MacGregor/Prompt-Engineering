{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a279edd1-f4ff-4cc0-9e7b-bca9d92da629",
   "metadata": {},
   "source": [
    "# Initial output generation. Switch out model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6271e186-7c20-47ab-af3a-43d82ab3fadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# === File paths ===\n",
    "prompt_filename = r'C:\\PhD\\Prompt_Engineering\\Final_Prompts\\prompt1.txt'\n",
    "output_filename = r'C:\\PhD\\Prompt_Engineering\\Outputs\\Output1L.txt'\n",
    "\n",
    "# === Read the prompt from file ===\n",
    "with open(prompt_filename, 'r', encoding='utf-8') as f:\n",
    "    user_prompt = f.read()\n",
    "\n",
    "# === Send prompt to Ollama ===\n",
    "try:\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            'model': 'llama3.2',\n",
    "            'prompt': user_prompt,\n",
    "            'stream': False,\n",
    "            'temperature': 0.0,\n",
    "            'top_p': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # === Parse JSON response ===\n",
    "    response_json = response.json()\n",
    "    result_text = response_json.get('response', '').strip()\n",
    "\n",
    "    # === Print and save the response ===\n",
    "    print(\"Response:\\n\", result_text)\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(result_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error during request:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce43800e-9204-4cf6-ba8d-57604a332315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# === File paths ===\n",
    "prompt_filename = r'C:\\PhD\\Prompt_Engineering\\Final_Prompts\\prompt2.txt'\n",
    "output_filename = r'C:\\PhD\\Prompt_Engineering\\Outputs\\Output2L.txt'\n",
    "\n",
    "# === Read the prompt from file ===\n",
    "with open(prompt_filename, 'r', encoding='utf-8') as f:\n",
    "    user_prompt = f.read()\n",
    "\n",
    "# === Send prompt to Ollama ===\n",
    "try:\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            'model': 'llama3.2',\n",
    "            'prompt': user_prompt,\n",
    "            'stream': False,\n",
    "            'temperature': 0.0,\n",
    "            'top_p': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # === Parse JSON response ===\n",
    "    response_json = response.json()\n",
    "    result_text = response_json.get('response', '').strip()\n",
    "\n",
    "    # === Print and save the response ===\n",
    "    print(\"Response:\\n\", result_text)\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(result_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error during request:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1cfbfb-102f-4466-82b2-260d3c5ce0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# === File paths ===\n",
    "prompt_filename = r'C:\\PhD\\Prompt_Engineering\\Final_Prompts\\prompt3.txt'\n",
    "output_filename = r'C:\\PhD\\Prompt_Engineering\\Outputs\\Output3L.txt'\n",
    "\n",
    "# === Read the prompt from file ===\n",
    "with open(prompt_filename, 'r', encoding='utf-8') as f:\n",
    "    user_prompt = f.read()\n",
    "\n",
    "# === Send prompt to Ollama ===\n",
    "try:\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            'model': 'llama3.2',\n",
    "            'prompt': user_prompt,\n",
    "            'stream': False,\n",
    "            'temperature': 0.0,\n",
    "            'top_p': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # === Parse JSON response ===\n",
    "    response_json = response.json()\n",
    "    result_text = response_json.get('response', '').strip()\n",
    "\n",
    "    # === Print and save the response ===\n",
    "    print(\"Response:\\n\", result_text)\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(result_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error during request:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a4f2e4-2676-4d91-a1b0-dad6ec9943c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# === File paths ===\n",
    "prompt_filename = r'C:\\PhD\\Prompt_Engineering\\Final_Prompts\\prompt1o.txt'\n",
    "output_filename = r'C:\\PhD\\Prompt_Engineering\\Outputs\\Output1oL.txt'\n",
    "\n",
    "# === Read the prompt from file ===\n",
    "with open(prompt_filename, 'r', encoding='utf-8') as f:\n",
    "    user_prompt = f.read()\n",
    "\n",
    "# === Send prompt to Ollama ===\n",
    "try:\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            'model': 'llama3.2',\n",
    "            'prompt': user_prompt,\n",
    "            'stream': False,\n",
    "            'temperature': 0.0,\n",
    "            'top_p': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # === Parse JSON response ===\n",
    "    response_json = response.json()\n",
    "    result_text = response_json.get('response', '').strip()\n",
    "\n",
    "    # === Print and save the response ===\n",
    "    print(\"Response:\\n\", result_text)\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(result_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error during request:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870ed2f6-8af8-4fde-b653-8a0139cd57ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# === File paths ===\n",
    "prompt_filename = r'C:\\PhD\\Prompt_Engineering\\Final_Prompts\\prompt2o.txt'\n",
    "output_filename = r'C:\\PhD\\Prompt_Engineering\\Outputs\\Output2oL.txt'\n",
    "\n",
    "# === Read the prompt from file ===\n",
    "with open(prompt_filename, 'r', encoding='utf-8') as f:\n",
    "    user_prompt = f.read()\n",
    "\n",
    "# === Send prompt to Ollama ===\n",
    "try:\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            'model': 'llama3.2',\n",
    "            'prompt': user_prompt,\n",
    "            'stream': False,\n",
    "            'temperature': 0.0,\n",
    "            'top_p': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # === Parse JSON response ===\n",
    "    response_json = response.json()\n",
    "    result_text = response_json.get('response', '').strip()\n",
    "\n",
    "    # === Print and save the response ===\n",
    "    print(\"Response:\\n\", result_text)\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(result_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error during request:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beddbd4-8c41-4cf1-abee-71c4dc2aad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# === File paths ===\n",
    "prompt_filename = r'C:\\PhD\\Prompt_Engineering\\Final_Prompts\\prompt4.txt'\n",
    "output_filename = r'C:\\PhD\\Prompt_Engineering\\Outputs\\Output4L.txt'\n",
    "\n",
    "# === Read the prompt from file ===\n",
    "with open(prompt_filename, 'r', encoding='utf-8') as f:\n",
    "    user_prompt = f.read()\n",
    "\n",
    "# === Send prompt to Ollama ===\n",
    "try:\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            'model': 'llama3.2',\n",
    "            'prompt': user_prompt,\n",
    "            'stream': False,\n",
    "            'temperature': 0.0,\n",
    "            'top_p': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # === Parse JSON response ===\n",
    "    response_json = response.json()\n",
    "    result_text = response_json.get('response', '').strip()\n",
    "\n",
    "    # === Print and save the response ===\n",
    "    print(\"Response:\\n\", result_text)\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(result_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error during request:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbca1086-8e4e-45d7-a7d5-15d18b46e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# === File paths ===\n",
    "prompt_filename = r'C:\\PhD\\Prompt_Engineering\\Final_Prompts\\prompt5.txt'\n",
    "output_filename = r'C:\\PhD\\Prompt_Engineering\\Outputs\\Output5L.txt'\n",
    "\n",
    "# === Read the prompt from file ===\n",
    "with open(prompt_filename, 'r', encoding='utf-8') as f:\n",
    "    user_prompt = f.read()\n",
    "\n",
    "# === Send prompt to Ollama ===\n",
    "try:\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            'model': 'llama3.2',\n",
    "            'prompt': user_prompt,\n",
    "            'stream': False,\n",
    "            'temperature': 0.0,\n",
    "            'top_p': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # === Parse JSON response ===\n",
    "    response_json = response.json()\n",
    "    result_text = response_json.get('response', '').strip()\n",
    "\n",
    "    # === Print and save the response ===\n",
    "    print(\"Response:\\n\", result_text)\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(result_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error during request:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2f86e9-ff1b-44f7-8ef8-4c81ebca4f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# === File paths ===\n",
    "prompt_filename = r'C:\\PhD\\Prompt_Engineering\\Final_Prompts\\prompt6.txt'\n",
    "output_filename = r'C:\\PhD\\Prompt_Engineering\\Outputs\\Output6L.txt'\n",
    "\n",
    "# === Read the prompt from file ===\n",
    "with open(prompt_filename, 'r', encoding='utf-8') as f:\n",
    "    user_prompt = f.read()\n",
    "\n",
    "# === Send prompt to Ollama ===\n",
    "try:\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            'model': 'llama3.2',\n",
    "            'prompt': user_prompt,\n",
    "            'stream': False,\n",
    "            'temperature': 0.0,\n",
    "            'top_p': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # === Parse JSON response ===\n",
    "    response_json = response.json()\n",
    "    result_text = response_json.get('response', '').strip()\n",
    "\n",
    "    # === Print and save the response ===\n",
    "    print(\"Response:\\n\", result_text)\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(result_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error during request:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822887ec-7bcc-44cf-bf25-a59013b018c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# === File paths ===\n",
    "prompt_filename = r'C:\\PhD\\Prompt_Engineering\\Final_Prompts\\prompt4o.txt'\n",
    "output_filename = r'C:\\PhD\\Prompt_Engineering\\Outputs\\Output4oL.txt'\n",
    "\n",
    "# === Read the prompt from file ===\n",
    "with open(prompt_filename, 'r', encoding='utf-8') as f:\n",
    "    user_prompt = f.read()\n",
    "\n",
    "# === Send prompt to Ollama ===\n",
    "try:\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            'model': 'llama3.2',\n",
    "            'prompt': user_prompt,\n",
    "            'stream': False,\n",
    "            'temperature': 0.0,\n",
    "            'top_p': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # === Parse JSON response ===\n",
    "    response_json = response.json()\n",
    "    result_text = response_json.get('response', '').strip()\n",
    "\n",
    "    # === Print and save the response ===\n",
    "    print(\"Response:\\n\", result_text)\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(result_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error during request:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b486325d-fc59-48c8-bd1f-0095c32ee9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# === File paths ===\n",
    "prompt_filename = r'C:\\PhD\\Prompt_Engineering\\Final_Prompts\\prompt7.txt'\n",
    "output_filename = r'C:\\PhD\\Prompt_Engineering\\Outputs\\Output7L.txt'\n",
    "\n",
    "# === Read the prompt from file ===\n",
    "with open(prompt_filename, 'r', encoding='utf-8') as f:\n",
    "    user_prompt = f.read()\n",
    "\n",
    "# === Send prompt to Ollama ===\n",
    "try:\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            'model': 'llama3.2',\n",
    "            'prompt': user_prompt,\n",
    "            'stream': False,\n",
    "            'temperature': 0.0,\n",
    "            'top_p': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # === Parse JSON response ===\n",
    "    response_json = response.json()\n",
    "    result_text = response_json.get('response', '').strip()\n",
    "\n",
    "    # === Print and save the response ===\n",
    "    print(\"Response:\\n\", result_text)\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(result_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error during request:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665e7508-49ab-4273-a455-e56065fad0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# === File paths ===\n",
    "prompt_filename = r'C:\\PhD\\Prompt_Engineering\\Final_Prompts\\prompt8.txt'\n",
    "output_filename = r'C:\\PhD\\Prompt_Engineering\\Outputs\\Output8L.txt'\n",
    "\n",
    "# === Read the prompt from file ===\n",
    "with open(prompt_filename, 'r', encoding='utf-8') as f:\n",
    "    user_prompt = f.read()\n",
    "\n",
    "# === Send prompt to Ollama ===\n",
    "try:\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            'model': 'llama3.2',\n",
    "            'prompt': user_prompt,\n",
    "            'stream': False,\n",
    "            'temperature': 0.0,\n",
    "            'top_p': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # === Parse JSON response ===\n",
    "    response_json = response.json()\n",
    "    result_text = response_json.get('response', '').strip()\n",
    "\n",
    "    # === Print and save the response ===\n",
    "    print(\"Response:\\n\", result_text)\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(result_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error during request:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496130cd-3720-4464-9abc-28b6c9d133f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# === File paths ===\n",
    "prompt_filename = r'C:\\PhD\\Prompt_Engineering\\Final_Prompts\\prompt9.txt'\n",
    "output_filename = r'C:\\PhD\\Prompt_Engineering\\Outputs\\Output9L.txt'\n",
    "\n",
    "# === Read the prompt from file ===\n",
    "with open(prompt_filename, 'r', encoding='utf-8') as f:\n",
    "    user_prompt = f.read()\n",
    "\n",
    "# === Send prompt to Ollama ===\n",
    "try:\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            'model': 'llama3.2',\n",
    "            'prompt': user_prompt,\n",
    "            'stream': False,\n",
    "            'temperature': 0.0,\n",
    "            'top_p': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # === Parse JSON response ===\n",
    "    response_json = response.json()\n",
    "    result_text = response_json.get('response', '').strip()\n",
    "\n",
    "    # === Print and save the response ===\n",
    "    print(\"Response:\\n\", result_text)\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(result_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error during request:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7861da4c-768e-40ce-b4b3-ff957f731d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# === File paths ===\n",
    "prompt_filename = r'C:\\PhD\\Prompt_Engineering\\Final_Prompts\\prompt7o.txt'\n",
    "output_filename = r'C:\\PhD\\Prompt_Engineering\\Outputs\\Output7oL.txt'\n",
    "\n",
    "# === Read the prompt from file ===\n",
    "with open(prompt_filename, 'r', encoding='utf-8') as f:\n",
    "    user_prompt = f.read()\n",
    "\n",
    "# === Send prompt to Ollama ===\n",
    "try:\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            'model': 'llama3.2',\n",
    "            'prompt': user_prompt,\n",
    "            'stream': False,\n",
    "            'temperature': 0.0,\n",
    "            'top_p': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # === Parse JSON response ===\n",
    "    response_json = response.json()\n",
    "    result_text = response_json.get('response', '').strip()\n",
    "\n",
    "    # === Print and save the response ===\n",
    "    print(\"Response:\\n\", result_text)\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(result_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error during request:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f4e07-7939-47f2-ae6f-d2d29a32c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# === File paths ===\n",
    "prompt_filename = r'C:\\PhD\\Prompt_Engineering\\Final_Prompts\\prompt10.txt'\n",
    "output_filename = r'C:\\PhD\\Prompt_Engineering\\Outputs\\Output10L.txt'\n",
    "\n",
    "# === Read the prompt from file ===\n",
    "with open(prompt_filename, 'r', encoding='utf-8') as f:\n",
    "    user_prompt = f.read()\n",
    "\n",
    "# === Send prompt to Ollama ===\n",
    "try:\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            'model': 'llama3.2',\n",
    "            'prompt': user_prompt,\n",
    "            'stream': False,\n",
    "            'temperature': 0.0,\n",
    "            'top_p': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # === Parse JSON response ===\n",
    "    response_json = response.json()\n",
    "    result_text = response_json.get('response', '').strip()\n",
    "\n",
    "    # === Print and save the response ===\n",
    "    print(\"Response:\\n\", result_text)\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(result_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error during request:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aada9416-51a2-493e-862b-a982a5731daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# === File paths ===\n",
    "prompt_filename = r'C:\\PhD\\Prompt_Engineering\\Final_Prompts\\prompt11.txt'\n",
    "output_filename = r'C:\\PhD\\Prompt_Engineering\\Outputs\\Output11L.txt'\n",
    "\n",
    "# === Read the prompt from file ===\n",
    "with open(prompt_filename, 'r', encoding='utf-8') as f:\n",
    "    user_prompt = f.read()\n",
    "\n",
    "# === Send prompt to Ollama ===\n",
    "try:\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            'model': 'llama3.2',\n",
    "            'prompt': user_prompt,\n",
    "            'stream': False,\n",
    "            'temperature': 0.0,\n",
    "            'top_p': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # === Parse JSON response ===\n",
    "    response_json = response.json()\n",
    "    result_text = response_json.get('response', '').strip()\n",
    "\n",
    "    # === Print and save the response ===\n",
    "    print(\"Response:\\n\", result_text)\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(result_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error during request:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa32972a-00e9-43d2-a2ea-a66a03922bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# === File paths ===\n",
    "prompt_filename = r'C:\\PhD\\Prompt_Engineering\\Final_Prompts\\prompt12.txt'\n",
    "output_filename = r'C:\\PhD\\Prompt_Engineering\\Outputs\\Output12L.txt'\n",
    "\n",
    "# === Read the prompt from file ===\n",
    "with open(prompt_filename, 'r', encoding='utf-8') as f:\n",
    "    user_prompt = f.read()\n",
    "\n",
    "# === Send prompt to Ollama ===\n",
    "try:\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            'model': 'llama3.2',\n",
    "            'prompt': user_prompt,\n",
    "            'stream': False,\n",
    "            'temperature': 0.0,\n",
    "            'top_p': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # === Parse JSON response ===\n",
    "    response_json = response.json()\n",
    "    result_text = response_json.get('response', '').strip()\n",
    "\n",
    "    # === Print and save the response ===\n",
    "    print(\"Response:\\n\", result_text)\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(result_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error during request:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d32c44-02fd-4c33-a74c-ef8a1e63f2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# === File paths ===\n",
    "prompt_filename = r'C:\\PhD\\Prompt_Engineering\\Final_Prompts\\prompt10o.txt'\n",
    "output_filename = r'C:\\PhD\\Prompt_Engineering\\Outputs\\Output10oL.txt'\n",
    "\n",
    "# === Read the prompt from file ===\n",
    "with open(prompt_filename, 'r', encoding='utf-8') as f:\n",
    "    user_prompt = f.read()\n",
    "\n",
    "# === Send prompt to Ollama ===\n",
    "try:\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            'model': 'llama3.2',\n",
    "            'prompt': user_prompt,\n",
    "            'stream': False,\n",
    "            'temperature': 0.0,\n",
    "            'top_p': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # === Parse JSON response ===\n",
    "    response_json = response.json()\n",
    "    result_text = response_json.get('response', '').strip()\n",
    "\n",
    "    # === Print and save the response ===\n",
    "    print(\"Response:\\n\", result_text)\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(result_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error during request:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad09d7-6d86-4de6-b71c-35438aa60153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# === File paths ===\n",
    "prompt_filename = r'C:\\PhD\\Prompt_Engineering\\Final_Prompts\\prompt13.txt'\n",
    "output_filename = r'C:\\PhD\\Prompt_Engineering\\Outputs\\Output13L.txt'\n",
    "\n",
    "# === Read the prompt from file ===\n",
    "with open(prompt_filename, 'r', encoding='utf-8') as f:\n",
    "    user_prompt = f.read()\n",
    "\n",
    "# === Send prompt to Ollama ===\n",
    "try:\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            'model': 'llama3.2',\n",
    "            'prompt': user_prompt,\n",
    "            'stream': False,\n",
    "            'temperature': 0.0,\n",
    "            'top_p': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # === Parse JSON response ===\n",
    "    response_json = response.json()\n",
    "    result_text = response_json.get('response', '').strip()\n",
    "\n",
    "    # === Print and save the response ===\n",
    "    print(\"Response:\\n\", result_text)\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(result_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error during request:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83e86a8-c78d-4216-b8a6-1e7e03c91380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# === File paths ===\n",
    "prompt_filename = r'C:\\PhD\\Prompt_Engineering\\Final_Prompts\\prompt14.txt'\n",
    "output_filename = r'C:\\PhD\\Prompt_Engineering\\Outputs\\Output14L.txt'\n",
    "\n",
    "# === Read the prompt from file ===\n",
    "with open(prompt_filename, 'r', encoding='utf-8') as f:\n",
    "    user_prompt = f.read()\n",
    "\n",
    "# === Send prompt to Ollama ===\n",
    "try:\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            'model': 'llama3.2',\n",
    "            'prompt': user_prompt,\n",
    "            'stream': False,\n",
    "            'temperature': 0.0,\n",
    "            'top_p': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # === Parse JSON response ===\n",
    "    response_json = response.json()\n",
    "    result_text = response_json.get('response', '').strip()\n",
    "\n",
    "    # === Print and save the response ===\n",
    "    print(\"Response:\\n\", result_text)\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(result_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error during request:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd1fa16-5641-4ed5-becc-1b262c50fb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# === File paths ===\n",
    "prompt_filename = r'C:\\PhD\\Prompt_Engineering\\Final_Prompts\\prompt15.txt'\n",
    "output_filename = r'C:\\PhD\\Prompt_Engineering\\Outputs\\Output15L.txt'\n",
    "\n",
    "# === Read the prompt from file ===\n",
    "with open(prompt_filename, 'r', encoding='utf-8') as f:\n",
    "    user_prompt = f.read()\n",
    "\n",
    "# === Send prompt to Ollama ===\n",
    "try:\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            'model': 'llama3.2',\n",
    "            'prompt': user_prompt,\n",
    "            'stream': False,\n",
    "            'temperature': 0.0,\n",
    "            'top_p': 1.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # === Parse JSON response ===\n",
    "    response_json = response.json()\n",
    "    result_text = response_json.get('response', '').strip()\n",
    "\n",
    "    # === Print and save the response ===\n",
    "    print(\"Response:\\n\", result_text)\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(result_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error during request:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39665a1f-9371-4a2d-b87e-ee837da2e24f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
